# Fine-Tuning LLM Model using Domain-Specific Text Data

This repository documents the process of fine-tuning a Large Language Model (LLM), specifically Llama2, using domain-specific data. The goal is to enhance the model's performance and applicability within a specific field or subject area. In this case, I leverage the power of AWS SageMaker and PyTorch within Jupyter Notebooks for the fine-tuning process.